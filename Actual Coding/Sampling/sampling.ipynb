{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fcce7f6-84b9-41cd-8c55-e20e73e03111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from striprtf.striprtf import rtf_to_text\n",
    "import json\n",
    "import pandas as pd\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9967970c-ad13-454d-99b6-da2071f3e6c6",
   "metadata": {},
   "source": [
    "### Convert the rft file into a JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b79b0d-85be-41c0-8c31-8ee18c060a9a",
   "metadata": {},
   "source": [
    "Data **before** Trump's first inauguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2af40f8-5bf2-4ca8-8fa4-a6f929631f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1730 records into raw_data_before.json\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Read RTF\n",
    "with open('raw_data_before.rtf', 'r', encoding='utf-8') as file:\n",
    "    rtf_content = file.read()\n",
    "\n",
    "# Step 2: Convert to plain text\n",
    "plain_text = rtf_to_text(rtf_content)\n",
    "\n",
    "# Step 3: Load JSON\n",
    "try:\n",
    "    data_1 = json.loads(plain_text)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Failed to decode JSON:\", e)\n",
    "    data_1 = []\n",
    "\n",
    "# Step 4: Save to JSON file\n",
    "if data_1:\n",
    "    with open('raw_data_before.json', 'w', encoding='utf-8', errors='replace') as f:\n",
    "        json.dump(data_1, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"Saved {len(data_1)} records into raw_data_before.json\")\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f07a4-f97a-4dab-b6e9-29ea856c6fc3",
   "metadata": {},
   "source": [
    "Data **after** Trump's first inauguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ff6f18-3918-45e5-9e86-1561c12bd484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 943 records into raw_data_after.json\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Read RTF\n",
    "with open('raw_data_after.rtf', 'r', encoding='utf-8') as file:\n",
    "    rtf_content = file.read()\n",
    "\n",
    "# Step 2: Convert to plain text\n",
    "plain_text = rtf_to_text(rtf_content)\n",
    "\n",
    "# Step 3: Load JSON\n",
    "try:\n",
    "    data_2 = json.loads(plain_text)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Failed to decode JSON:\", e)\n",
    "    data_2 = []\n",
    "\n",
    "# Step 4: Save to JSON file\n",
    "if data_2:\n",
    "    with open('raw_data_after.json', 'w', encoding='utf-8', errors='replace') as f:\n",
    "        json.dump(data_2, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"Saved {len(data_2)} records into raw_data_after.json\")\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4ca416-21f0-451f-b273-270ee66df841",
   "metadata": {},
   "source": [
    "### Data cleaning & merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0e27d3d-10f2-4b12-8154-a0b7fddb0fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_1 = pd.read_json(\"raw_data_before.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb49bc98-aab7-49b7-8f08-7cbe890f6a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_2 = pd.read_json(\"raw_data_after.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae651ec2-245e-4797-aeeb-f37178a24c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_raw_data = pd.concat([raw_data_1, raw_data_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70698431-c478-4ebc-8361-e02121cb2e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_raw_data = merged_raw_data.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad7c0cd-dc8f-4f3d-9958-98fb9d7488e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where the 'date' is July 24, 2017 (CET) - only 2 posts in the dataset\n",
    "filtered_raw_data = sorted_raw_data[sorted_raw_data['date'].dt.date != pd.to_datetime('2017-07-24').date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77736e75-d9e6-47d7-b50f-2719afdfd62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filtered_raw_data[['date', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d757667-b1af-4db5-ae70-1c606452dabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 2671 posts in the downloaded dataset (without retweets).\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are a total of {len(data)} posts in the downloaded dataset (without retweets).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0904d78d-ed3c-41ca-b085-fc27808b24c5",
   "metadata": {},
   "source": [
    "### Systematic random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03c476f0-c8f0-4068-9290-5c7c38e5b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = len(data) / 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99cad756-a4cd-4862-bbd6-90f2f5d0c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indexes = [int(i * interval) for i in range(1200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59e54465-d1ae-49bd-b506-ba29c95acd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indexes = [idx for idx in sample_indexes if idx < len(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e17509b-74da-49fd-987f-b60284b90b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = data.iloc[sample_indexes].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6fd52f-90c8-4a00-a216-c73191b3fe4b",
   "metadata": {},
   "source": [
    "### Pseudonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f18391d-1768-4efc-8bf8-2401eea27854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate random pseudonym\n",
    "def generate_pseudonym():\n",
    "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=6))\n",
    "\n",
    "# Create pseudonym list\n",
    "unique_ids = set()\n",
    "while len(unique_ids) < len(sampled_data):\n",
    "    unique_ids.add(generate_pseudonym())\n",
    "\n",
    "pseudonyms = list(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38fd7e67-d288-429b-b816-4fa899212d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data['pseudID'] = pseudonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ad9c641-8cae-4310-b65a-cd23f5eb8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data.to_excel('1200_sampled_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcc7e75-4631-46e8-93a0-92f1eb385d70",
   "metadata": {},
   "source": [
    "### Prepare the Excel files for each coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58e861a2-636e-413c-97a4-9d1c4aba271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coders = ['Luke', 'Ada', 'Mare', 'Francesco']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ecc5ba7-26fe-455d-bff5-289ab3a01875",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data['coder'] = sampled_data.index.map(lambda x: coders[x % 4]) # assign coder based on row number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4534f22-8f03-488f-a80b-e4c8ad814e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data['postID'] = range(1, len(sampled_data) + 1) # post ID starts from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82b94bff-4ec1-4a63-99bb-687dc46db509",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coder in coders:\n",
    "    # Get the subset for the coder\n",
    "    coder_data = sampled_data[sampled_data['coder'] == coder][['postID', 'text', 'pseudID']].copy()\n",
    "\n",
    "    # Shuffle the rows\n",
    "    coder_data = coder_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Extract initial letter from coder's name\n",
    "    initial = coder[0].upper()  # 'Luke' -> 'L', 'Ada' -> 'A', etc.\n",
    "    \n",
    "    # Re-assign postID as 1L, 2L, 3L, etc.\n",
    "    coder_data['postID'] = [f\"{i+1}{initial}\" for i in range(len(coder_data))]\n",
    "    \n",
    "    # Create an Excel file for each coder\n",
    "    filename = f\"{coder.replace(' ', '_')}_posts.xlsx\"\n",
    "    coder_data.to_excel(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb1555-0392-4b79-a529-718b44a31a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
